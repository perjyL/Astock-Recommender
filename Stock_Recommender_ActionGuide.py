import argparse
from datetime import datetime
import os
import numpy as np
import pandas as pd

from src.config import (
    INDEX_CODE,
    MODEL_TYPE_REG,
    FEATURE_COLS,
    PORTFOLIO_TARGET_COL,
    HOLD_N,
    TOP_K,
    MIN_TRAIN_SIZE,
    WEIGHT_MODE,
    SOFTMAX_TAU,
    COST_RATE,
)
from src.data_loader import (
    get_index_constituents,
    get_index_constituents_with_name,
    get_hs300_index,
    get_stock_history,
)
from src.feature_engineering import add_features
from src.model import train_model_reg
from src.backtest_portfolio import _calc_weights, _normalize_model_type


def _pick_signal_date(index_code: str):
    """ä¼˜å…ˆç”¨æŒ‡æ•°è¡Œæƒ…çš„æœ€åäº¤æ˜“æ—¥ä½œä¸ºä¿¡å·æ—¥æœŸã€‚"""
    index_df = get_hs300_index(index_code)
    if index_df is not None and not index_df.empty:
        return pd.to_datetime(index_df.index.max())
    return None


def _format_pct(x):
    if x is None or not np.isfinite(x):
        return "N/A"
    return f"{x:.2%}"


def generate_next_day_guide(capital: float = 1_000_000.0, use_realtime: bool = False):
    # 1) åŸºæœ¬ä¿¡æ¯
    hold_steps = max(1, HOLD_N - 1)
    bucket_ratio = 1.0 / hold_steps
    model_type_norm = _normalize_model_type(MODEL_TYPE_REG)

    print("\n==============================")
    print("ğŸ“Œ æ˜æ—¥æ“ä½œè¡ŒåŠ¨æŒ‡å—ï¼ˆåŸºäº backtest_portfolio é€»è¾‘ï¼‰")
    print(f"æŒ‡æ•°: {INDEX_CODE}")
    print(f"æ¨¡å‹: {MODEL_TYPE_REG} (norm -> {model_type_norm})")
    print(f"TopK: {TOP_K} | é¢„æµ‹ç›®æ ‡: {PORTFOLIO_TARGET_COL}")
    print(f"æƒé‡æ–¹å¼: {WEIGHT_MODE} | Softmax Tau: {SOFTMAX_TAU}")
    print(f"N(é¢„æµ‹/æŒæœ‰çª—å£): {HOLD_N}  -> åˆ†æ¡¶æ•° = N-1 = {hold_steps}")
    print(f"å•è¾¹æˆæœ¬å‡è®¾: {COST_RATE:.2%}")
    print(f"æ€»èµ„é‡‘: {capital:,.2f}")
    print("==============================\n")

    # 2) è·å–æˆåˆ†è‚¡åˆ—è¡¨
    name_map = get_index_constituents_with_name(INDEX_CODE)
    symbols = list(name_map.keys()) if name_map else get_index_constituents(INDEX_CODE)
    if not symbols:
        print(f"âŒ æŒ‡æ•° {INDEX_CODE} æˆåˆ†è‚¡ä¸ºç©ºï¼Œæ— æ³•ç”Ÿæˆè¡ŒåŠ¨æŒ‡å—")
        return None

    # 3) ä¿¡å·æ—¥æœŸï¼ˆæœ€åäº¤æ˜“æ—¥ï¼‰
    signal_date = _pick_signal_date(INDEX_CODE)
    if signal_date is None:
        print("âŒ æœªèƒ½è·å–æŒ‡æ•°äº¤æ˜“æ—¥ï¼Œæ— æ³•ç”Ÿæˆè¡ŒåŠ¨æŒ‡å—")
        return None

    print(f"ä¿¡å·æ—¥æœŸï¼ˆT æ—¥æ”¶ç›˜æ•°æ®ï¼‰: {signal_date.date()}")
    print("æ˜æ—¥æ‰§è¡Œæ—¥æœŸï¼ˆT+1ï¼‰: ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥")

    # 4) é€è‚¡è®­ç»ƒä¸é¢„æµ‹
    preds = []
    skipped = 0
    for s in symbols:
        name = name_map.get(s, s)
        try:
            df = get_stock_history(s, use_realtime=use_realtime)
            if df is None or df.empty:
                skipped += 1
                continue

            df = add_features(df)
            if signal_date not in df.index:
                skipped += 1
                continue

            # ä½¿ç”¨ signal_date å‰ä¸€å¤©çš„æ•°æ®è®­ç»ƒï¼Œé¿å…æœªæ¥ä¿¡æ¯
            train_df = df.loc[:signal_date].iloc[:-1]
            train_df = train_df[FEATURE_COLS + [PORTFOLIO_TARGET_COL]].dropna()
            if len(train_df) < MIN_TRAIN_SIZE:
                skipped += 1
                continue

            X_train = train_df[FEATURE_COLS]
            y_train = train_df[PORTFOLIO_TARGET_COL]
            model = train_model_reg(X_train, y_train, model_type=MODEL_TYPE_REG)

            X_test = df.loc[[signal_date], FEATURE_COLS].dropna()
            if X_test.empty:
                skipped += 1
                continue

            pred = float(model.predict(X_test)[0])
            if not np.isfinite(pred):
                skipped += 1
                continue

            preds.append((s, name, pred))
        except Exception:
            skipped += 1
            continue

    if len(preds) < TOP_K:
        print(f"âŒ å¯ç”¨æ ·æœ¬ä¸è¶³ï¼ˆ{len(preds)} < TOP_K={TOP_K}ï¼‰ï¼Œæ— æ³•ç”Ÿæˆè¡ŒåŠ¨æŒ‡å—")
        return None

    # 5) é€‰ TopK + æƒé‡
    pred_df = pd.DataFrame(preds, columns=["Code", "Name", "Pred_Return"])
    top_df = pred_df.sort_values("Pred_Return", ascending=False).head(TOP_K).reset_index(drop=True)
    weights = _calc_weights(top_df["Pred_Return"].values)
    top_df["Weight_in_Bucket"] = weights
    top_df["Capital_in_Bucket"] = capital * bucket_ratio * top_df["Weight_in_Bucket"]
    top_df.insert(0, "Rank", range(1, len(top_df) + 1))

    # 6) è¾“å‡ºè¡ŒåŠ¨æŒ‡å—
    print("\n===== æ˜æ—¥è¡ŒåŠ¨æŒ‡å—ï¼ˆT+1ï¼‰=====")
    print("æ“ä½œåŸåˆ™ï¼ˆä¸ backtest_portfolio ä¸€è‡´ï¼‰ï¼š")
    print("1) ä¿¡å·æ¥è‡ª T æ—¥æ”¶ç›˜æ•°æ®ï¼ŒT+1 æ”¶ç›˜å»ºä»“")
    if hold_steps > 1:
        print(f"2) èµ„é‡‘åˆ† {hold_steps} ä»½ï¼Œæ¯æ—¥ä»…æŠ•å…¥ {bucket_ratio:.2%} æ€»èµ„é‡‘")
        print(f"3) æ¯ä¸ªæ¡¶æŒæœ‰ {hold_steps} ä¸ªäº¤æ˜“æ—¥ï¼Œåˆ°æœŸé‡Šæ”¾èµ„é‡‘")
    else:
        print("2) HOLD_N=1ï¼šæ¯å¤©å¯ä»¥ä½¿ç”¨å…¨éƒ¨èµ„é‡‘åšå•æ—¥æŒæœ‰")
    print("4) æƒé‡æŒ‰ç­–ç•¥è®¡ç®—ï¼ˆequal/proportional/softmaxï¼‰")
    print("5) ä»¥ä¸‹ä¸ºæ˜æ—¥å»ºè®®æ–°å¼€ä»“åå•ï¼š\n")

    for _, row in top_df.iterrows():
        print(
            f"#{int(row['Rank']):02d} {row['Code']} {row['Name']} | "
            f"é¢„æµ‹æœªæ¥æ”¶ç›Š={_format_pct(row['Pred_Return'])} | "
            f"æ¡¶å†…æƒé‡={row['Weight_in_Bucket']:.2%} | "
            f"å»ºè®®æŠ•å…¥={row['Capital_in_Bucket']:,.2f}"
        )

    # 7) ä¿å­˜ CSV
    os.makedirs("output", exist_ok=True)
    out_path = "output/next_day_action_guide.csv"
    top_df.to_csv(out_path, index=False, encoding="utf-8-sig")
    print(f"\nâœ… æ˜æ—¥è¡ŒåŠ¨æŒ‡å—å·²ä¿å­˜ï¼š{out_path}")
    print(f"æœ¬æ¬¡è·³è¿‡è‚¡ç¥¨æ•°é‡ï¼š{skipped}")
    return top_df


def parse_args():
    parser = argparse.ArgumentParser(description="ç”Ÿæˆæ˜æ—¥æ“ä½œè¡ŒåŠ¨æŒ‡å—ï¼ˆTop-K ç­–ç•¥ï¼‰")
    parser.add_argument("--capital", type=float, default=1_000_000.0, help="æ€»èµ„é‡‘ï¼ˆç”¨äºè®¡ç®—å»ºè®®æŠ•å…¥é‡‘é¢ï¼‰")
    parser.add_argument("--use-realtime", action="store_true", help="ä½¿ç”¨å®æ—¶è¡Œæƒ…è¦†ç›–å½“æ—¥æ•°æ®")
    return parser.parse_args()


if __name__ == "__main__":
    args = parse_args()
    generate_next_day_guide(capital=args.capital, use_realtime=args.use_realtime)
